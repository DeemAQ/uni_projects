{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofbFP6L6DSS7"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avt89UbqSClQ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owzU3eFr8V70"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Mb2R816DEpM"
      },
      "source": [
        "# Reading dataset and visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZN1Q_avR4zf"
      },
      "source": [
        "def visualize(df):\n",
        "    print('HEAD\\n')\n",
        "    print(df.head())\n",
        "    print('\\n\\nDATA TYPES\\n')\n",
        "    print(df.dtypes)\n",
        "    print('\\n\\nINFORMATION\\n')\n",
        "    print(df.info())\n",
        "\n",
        "    # numerical statistics\n",
        "    print('\\n\\nSTATISTICS FOR NUMERICAL DATA:\\n')\n",
        "    print(df.describe().T)\n",
        "    # categorical statistics\n",
        "    print('\\n\\nSTATISTICS FOR CATEGORICAL DATA:\\n')\n",
        "    print(df.describe(include=('bool', 'category', 'object')).T)\n",
        "    print('\\n')\n",
        "\n",
        "\n",
        "    # Display label distribution. Do we have class imbalance? \n",
        "    graph = sns.displot(df, x = 'Churn', hue='Churn')\n",
        "    graph.set_axis_labels('Churn', 'Number in each label')\n",
        "    graph.set_titles('label distribution')\n",
        "\n",
        "\n",
        "    # Visualize the correlation between each feature and the label\n",
        "    correlations = df.corr()\n",
        "    sort_corr_cols = correlations.Churn.sort_values(ascending=False).keys()\n",
        "    sorted_corr = correlations.loc[sort_corr_cols, sort_corr_cols]\n",
        "    print(sorted_corr)\n",
        "    corr_mask = np.zeros_like(correlations)\n",
        "    corr_mask[np.triu_indices_from(corr_mask)] = 1\n",
        "    # Make the figsize 9x9\n",
        "    plt.figure(figsize=(9,9))\n",
        "    # Plot heatmap of annotated correlations\n",
        "    sns.heatmap(sorted_corr*100, \n",
        "                    cmap='RdBu', \n",
        "                    annot=True,\n",
        "                    fmt='.0f',\n",
        "                    mask=corr_mask,\n",
        "                    cbar=False)\n",
        "    plt.title('Correlations by Churn', fontsize=14)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # Visualize the distribution for all continuous value features using histogram\n",
        "    df.hist(figsize=(19,19))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVPfoCYiC1c6"
      },
      "source": [
        "# Preprocess data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu97Pg4jNfyZ"
      },
      "source": [
        "OneHot encode using pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axx87aYkCN-H"
      },
      "source": [
        "def encode_and_bind(og_df, feature):\n",
        "    dummies = pd.get_dummies(og_df[[feature]])\n",
        "    result = pd.concat([og_df, dummies], axis=1)\n",
        "    result = result.drop([feature], axis=1)\n",
        "    return (result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHq55F9UNUHn"
      },
      "source": [
        "Clean the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2Z5BDXINvWW"
      },
      "source": [
        "def prepdata(data):\n",
        "    # drop unnacessrly columns \n",
        "    data = data.drop(columns=['Unnamed: 0', 'CLIENTNUM','Avg_Open_To_Buy','Months_on_book','Total_Trans_Ct','Total_Revolving_Bal'])\n",
        "    # drop null if any\n",
        "    data.dropna()\n",
        "    # drop dublicate if any \n",
        "    data.drop_duplicates(inplace=True)\n",
        "\n",
        "    cat_types = ['bool','object','category']\n",
        "    clean_data = data.copy()\n",
        "    clean_data[clean_data.select_dtypes(cat_types).columns] = clean_data.select_dtypes(cat_types).apply(lambda x : x.astype('category'))\n",
        "    features = clean_data.select_dtypes('category').columns.to_list()\n",
        "    for feature in features:\n",
        "        clean_data = encode_and_bind(clean_data, feature)\n",
        "        \n",
        "    return clean_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_9KAdwTS6Ih"
      },
      "source": [
        "def preprocess_data(train_X,test_X,train_y,test_y):\n",
        "    # train data\n",
        "    p_train_x = prepdata(train_X)\n",
        "\n",
        "    # test data\n",
        "    p_test_x = prepdata(test_X)\n",
        "\n",
        "    # scaling all the data [Numerical]\n",
        "    scaler = MinMaxScaler()\n",
        "    p_train_x = scaler.fit_transform(p_train_x)\n",
        "    p_test_x = scaler.fit_transform(p_test_x)\n",
        "\n",
        "    # we do not need to change anything in y since it's already represented as 0-1\n",
        "    p_train_y = train_y\n",
        "    p_test_y = test_y\n",
        "\n",
        "\n",
        "    return p_train_x, p_test_x, p_train_y, p_test_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVBa0-5aCuDU"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHedEMVFVplL"
      },
      "source": [
        "def plot_loss(model):\n",
        "    plt.plot(model.loss_curve_)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k__eKOVdWLiX"
      },
      "source": [
        "def predict_evalute(x_test, y_test, model):\n",
        "    y_predicted = model.predict(x_test)\n",
        "    \n",
        "    print('Classification Report')\n",
        "\n",
        "    report = classification_report(y_test, y_predicted, target_names=['0','1'])\n",
        "    print(report)\n",
        "\n",
        "    matrix = ConfusionMatrixDisplay.from_predictions(y_true=y_test, y_pred=y_predicted)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB1kKLg5N1YJ"
      },
      "source": [
        "MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQNQsq20SMmN"
      },
      "source": [
        "def train_mlp(x_test, y_test, inpu_dim):\n",
        "    mlp = MLPClassifier(max_iter=10)\n",
        "\n",
        "    parameter_space = {\n",
        "    'hidden_layer_sizes': (16, 32, 64),\n",
        "    'activation': ['logistic', 'relu'],\n",
        "    'solver': ['sgd'],\n",
        "    'alpha': [0.0001, 0.001, 0.01],\n",
        "    'learning_rate': ['constant','adaptive'], \n",
        "    }\n",
        "\n",
        "    gscv = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=10)\n",
        "    gscv.fit(x_train, y_train)\n",
        "    print('Best parameters found:\\n', gscv.best_params_)\n",
        "    print('Best achieved score:\\n', gscv.best_score_)\n",
        "\n",
        "    plot_loss(gscv.best_estimator_)\n",
        "\n",
        "    return gscv.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WuWBJ1NEHDd"
      },
      "source": [
        "Suggested Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHpyP98eELX6"
      },
      "source": [
        "def train(x_train, y_train):\n",
        "    mlp = MLPClassifier(max_iter=10, hidden_layer_sizes=(16, 32, 64, 128, 256))\n",
        "\n",
        "    parameter_space = {\n",
        "      'activation': ['relu'],\n",
        "      'solver': ['sgd'],\n",
        "      'alpha': [1e-2, 1e-3, 1e-4],\n",
        "      'learning_rate': ['constant','adaptive'], \n",
        "      }\n",
        "\n",
        "    gscv = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=10)\n",
        "    gscv.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "    print('Best parameters found:\\n', gscv.best_params_)\n",
        "    print('Best achieved score:\\n', gscv.best_score_)\n",
        "\n",
        "    plot_loss(gscv.best_estimator_)\n",
        "\n",
        "    return gscv.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7gsSMC-ZLE5"
      },
      "source": [
        "df = pd.read_csv(io.BytesIO(uploaded['BankChurners1.csv']))\n",
        "\n",
        "visualize(df)\n",
        "\n",
        "y = df['Churn']\n",
        "x = df.drop('Churn', errors='ignore', axis=1)\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, shuffle=True)\n",
        "x_train, x_test, y_train, y_test=preprocess_data(x_train, x_test, y_train, y_test)\n",
        "mlp_model = train_mlp(x_train, y_train, x_train.shape[1])\n",
        "print('\\n\\nMLP:\\n')\n",
        "predict_evalute(x_test, y_test, mlp_model)\n",
        "\n",
        "ann_model = train(x_train, y_train)\n",
        "print('\\n\\nANN:\\n')\n",
        "predict_evalute(x_test, y_test, ann_model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}